<?xml version="1.0"?>
<rss version="2.0">
    <channel>
        <title>Nineko&#39;s Blog</title>
        <link>https://nineko.github.io</link>
        <description></description>
        <language>zh-TW</language>
        <pubDate>Tue, 04 Aug 2020 11:15:06 +0800</pubDate>
        <lastBuildDate>Tue, 04 Aug 2020 11:15:06 +0800</lastBuildDate>
        <category>DNN</category>
        <category>QT</category>
        <category>Computer Vision</category>
        <category>Pose Estimation</category>
        <item>
            <guid isPermalink="true">https://nineko.github.io/2020/08/04/Note-Multi-Scale/</guid>
            <title>[筆記]序列模型(2)-多尺度架構</title>
            <link>https://nineko.github.io/2020/08/04/Note-Multi-Scale/</link>
            <category>DNN</category>
            <pubDate>Tue, 04 Aug 2020 11:15:06 +0800</pubDate>
            <description><![CDATA[ &lt;h1&gt;目錄&lt;/h1&gt;
&lt;p&gt;基本序列模型&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;多尺度架構&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;捷徑架構&lt;/p&gt;
&lt;h1&gt;多尺度架構&lt;/h1&gt;
&lt;hr&gt;
&lt;p&gt;  多尺度架構能夠在 GoogLeNet 中的 Inception 架構中廣泛看到，其概念想法為利用不同卷積核大小的卷積層來給予網路更多的選擇去擷取適當的特徵，在架構上，我們能夠把多尺度架構分成兩個步驟──分散及匯集；分散指的是將輸入分散至不同大小卷積核的卷積層，匯集則是將不同卷積層的結果重新組裝成一個張量，所以在進行卷積計算時，會利用 Padding 來確保輸出張量的長寬是一致的，圖解的話像是這種感覺。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;M1.png&#34; alt=&#34;image&#34;&gt;&lt;/p&gt;
&lt;p&gt;  可以看到為了進行多尺度的計算，我們無法去操作特徵圖的長寬，這意味著龐大的參數計算，為了緩和計算負擔，我們可以利用多次卷積降低兩維的大小，將資訊累積在深度上，多尺度計算時也可以利用 1x1 的卷積核來降低深度維度，使用這些技巧來建構多尺度架構，在結果與參數使用量上取得適當的平衡吧。&lt;/p&gt;
&lt;p&gt;接下來將會用簡單的範例來示範如何建構一個多尺度架構。&lt;/p&gt;
&lt;figure class=&#34;highlight python&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; tensorflow &lt;span class=&#34;keyword&#34;&gt;as&lt;/span&gt; tf&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; keras &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; backend &lt;span class=&#34;keyword&#34;&gt;as&lt;/span&gt; K&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; keras.models &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; Model&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; keras.layers &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; Conv2D,Input,concatenate&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;function&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title&#34;&gt;MultiScaleModel&lt;/span&gt;():&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;comment&#34;&gt;# 輸入層&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    model_input = Input(shape=(&lt;span class=&#34;number&#34;&gt;15&lt;/span&gt;,&lt;span class=&#34;number&#34;&gt;15&lt;/span&gt;,&lt;span class=&#34;number&#34;&gt;3&lt;/span&gt;), name=&lt;span class=&#34;string&#34;&gt;&amp;#x27;input&amp;#x27;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;comment&#34;&gt;#  1x1 卷積層&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    conv1 = Conv2D(&lt;span class=&#34;number&#34;&gt;10&lt;/span&gt;, (&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;), activation=&lt;span class=&#34;string&#34;&gt;&amp;#x27;relu&amp;#x27;&lt;/span&gt;, padding=&lt;span class=&#34;string&#34;&gt;&amp;#x27;same&amp;#x27;&lt;/span&gt; ,name=&lt;span class=&#34;string&#34;&gt;&amp;#x27;Conv_1_1&amp;#x27;&lt;/span&gt;)(model_input)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;comment&#34;&gt;#  3x3 卷積層&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    conv3 = Conv2D(&lt;span class=&#34;number&#34;&gt;20&lt;/span&gt;, (&lt;span class=&#34;number&#34;&gt;3&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;3&lt;/span&gt;), activation=&lt;span class=&#34;string&#34;&gt;&amp;#x27;relu&amp;#x27;&lt;/span&gt;, padding=&lt;span class=&#34;string&#34;&gt;&amp;#x27;same&amp;#x27;&lt;/span&gt; ,name=&lt;span class=&#34;string&#34;&gt;&amp;#x27;Conv_3_3&amp;#x27;&lt;/span&gt;)(model_input)  &lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;comment&#34;&gt;#  5x5 卷積層&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    conv5 = Conv2D(&lt;span class=&#34;number&#34;&gt;30&lt;/span&gt;, (&lt;span class=&#34;number&#34;&gt;5&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;5&lt;/span&gt;), activation=&lt;span class=&#34;string&#34;&gt;&amp;#x27;relu&amp;#x27;&lt;/span&gt;, padding=&lt;span class=&#34;string&#34;&gt;&amp;#x27;same&amp;#x27;&lt;/span&gt; ,name=&lt;span class=&#34;string&#34;&gt;&amp;#x27;Conv_5_5&amp;#x27;&lt;/span&gt;)(model_input)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;comment&#34;&gt;# 輸出層 - 進行 concatenate&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    model_output= concatenate([conv1, conv3, conv5] , axis=&lt;span class=&#34;number&#34;&gt;3&lt;/span&gt;,name=&lt;span class=&#34;string&#34;&gt;&amp;#x27;output&amp;#x27;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    model = Model(inputs=[model_input], outputs=[model_output])&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; model&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;使用 &lt;code&gt;model.summary()&lt;/code&gt;  可以更清楚的看到架構。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;M2.png&#34; alt=&#34;image&#34;&gt;&lt;/p&gt;
&lt;p&gt;這裡值得一提的是，在進行 concatenate 時，需要指定接合的維度。&lt;/p&gt;
&lt;figure class=&#34;highlight python&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;tf.keras.layers.Concatenate(axis=&lt;span class=&#34;number&#34;&gt;-1&lt;/span&gt;, **kwargs)&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;在這裡因為我們的卷積層輸出為 (None,15,15,10) 、 (None,15,15,20) 、 (None,15,15,30) ，需要接合的為第三維度，所以需要設定 &lt;code&gt;axis=3&lt;/code&gt; ，若想了解更多資訊，可以參考 &lt;a href=&#34;https://keras.io/api/layers/merging_layers/concatenate/&#34;&gt;Keras 手冊&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;  在範例中，我們只建構了一層最簡單的多尺度架構，在使用上這樣的一層只是一個 Block ，利用堆疊這些 Block 如同在建構一般卷積層一般，更深的層數意味著更複雜的特徵組合，然而比起普通卷積，多尺度的一層中包含了不同卷積核的特徵，多層疊加下會得到更複雜的特徵，給予我們設計網路架構時多了一種思路。&lt;/p&gt;
 ]]></description>
        </item>
        <item>
            <guid isPermalink="true">https://nineko.github.io/2020/08/03/Note-BasicSequenceModel/</guid>
            <title>[筆記]序列模型(1)-基本序列模型</title>
            <link>https://nineko.github.io/2020/08/03/Note-BasicSequenceModel/</link>
            <category>DNN</category>
            <pubDate>Mon, 03 Aug 2020 15:55:22 +0800</pubDate>
            <description><![CDATA[ &lt;h1&gt;目錄&lt;/h1&gt;
&lt;p&gt;&lt;strong&gt;基本序列模型&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;多尺度架構&lt;/p&gt;
&lt;p&gt;捷徑架構&lt;/p&gt;
&lt;h1&gt;基本序列模型&lt;/h1&gt;
&lt;hr&gt;
&lt;p&gt;  序列模型為建構深度學習網路時最直觀也最簡便的方式，在大多數時候，序列模型往往能夠讓你在解決問題上提供一個初步的解決方案。&lt;/p&gt;
&lt;p&gt;不過儘管它如此單純，依舊值得好好研究，在本篇中將會從最基本的開始說明，也就是沒有任何特別操作，單純一層疊一層的方式來建構深度學習網路。&lt;/p&gt;
&lt;p&gt;這種方式在初期被大量使用，它方便架設，也很容易理解，但是它因簡單的架構，無法處理太過於複雜的特徵，也沒有任何機制去降低計算量，可說是有利有弊。&lt;/p&gt;
&lt;h2&gt;建構&lt;/h2&gt;
&lt;hr&gt;
&lt;h3&gt;全連接層&lt;/h3&gt;
&lt;hr&gt;
&lt;p&gt;在這個筆記裡，範例皆為 Keras 實做版本，Keras 版本為 2.4.3 ，基底 Tensorflow 版本為 2.3.0 。&lt;/p&gt;
&lt;p&gt;假設我們想要建構一個輸入長度為 100 的向量，經過兩層輸出為 50 的隱藏層後，最後輸出長度為 10 的向量。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;M1.png&#34; alt=&#34;image&#34;&gt;&lt;/p&gt;
&lt;p&gt;在 Keras 中，我們可以使用很簡單的方式來建構一個序列模型。&lt;/p&gt;
&lt;figure class=&#34;highlight python&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; tensorflow &lt;span class=&#34;keyword&#34;&gt;as&lt;/span&gt; tf&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; keras.models &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; Model&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; keras.layers &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; Input,Dense&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; keras &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; backend &lt;span class=&#34;keyword&#34;&gt;as&lt;/span&gt; K&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;function&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title&#34;&gt;SequenceModel&lt;/span&gt;():&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;comment&#34;&gt;# 輸入層&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    model_input = Input(shape=(&lt;span class=&#34;number&#34;&gt;100&lt;/span&gt;), name=&lt;span class=&#34;string&#34;&gt;&amp;#x27;input&amp;#x27;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;comment&#34;&gt;# 隱藏層 1 &lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    hidden = Dense(&lt;span class=&#34;number&#34;&gt;50&lt;/span&gt;, activation=&lt;span class=&#34;string&#34;&gt;&amp;#x27;sigmoid&amp;#x27;&lt;/span&gt;,name=&lt;span class=&#34;string&#34;&gt;&amp;quot;hidden_1&amp;quot;&lt;/span&gt;)(model_input)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;comment&#34;&gt;# 隱藏層 2 &lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    hidden = Dense(&lt;span class=&#34;number&#34;&gt;50&lt;/span&gt;, activation=&lt;span class=&#34;string&#34;&gt;&amp;#x27;sigmoid&amp;#x27;&lt;/span&gt;,name=&lt;span class=&#34;string&#34;&gt;&amp;quot;hidden_2&amp;quot;&lt;/span&gt;)(hidden)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;comment&#34;&gt;# 輸出層 &lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    model_output = Dense(&lt;span class=&#34;number&#34;&gt;10&lt;/span&gt;, activation=&lt;span class=&#34;string&#34;&gt;&amp;#x27;sigmoid&amp;#x27;&lt;/span&gt;,name=&lt;span class=&#34;string&#34;&gt;&amp;quot;output&amp;quot;&lt;/span&gt;)(hidden)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    model = Model(inputs=[model_input], outputs=[model_output])&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; model&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;  可以看到由 Keras 建構只需要專心建構網路的架構，而不需要做 Weight 及 Bias 的數量及初始化定義，它會以預設的參數進行建構，若要修改也可以帶入引數進行設定。&lt;/p&gt;
&lt;figure class=&#34;highlight python&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;keras.layers.Dense(units, &lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;                   activation=&lt;span class=&#34;literal&#34;&gt;None&lt;/span&gt;, &lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;                   use_bias=&lt;span class=&#34;literal&#34;&gt;True&lt;/span&gt;, &lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;                   kernel_initializer=&lt;span class=&#34;string&#34;&gt;&amp;#x27;glorot_uniform&amp;#x27;&lt;/span&gt;, bias_initializer=&lt;span class=&#34;string&#34;&gt;&amp;#x27;zeros&amp;#x27;&lt;/span&gt;, &lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;                   kernel_regularizer=&lt;span class=&#34;literal&#34;&gt;None&lt;/span&gt;, &lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;                   bias_regularizer=&lt;span class=&#34;literal&#34;&gt;None&lt;/span&gt;, &lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;                   activity_regularizer=&lt;span class=&#34;literal&#34;&gt;None&lt;/span&gt;, &lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;                   kernel_constraint=&lt;span class=&#34;literal&#34;&gt;None&lt;/span&gt;, &lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;                   bias_constraint=&lt;span class=&#34;literal&#34;&gt;None&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;若要了解更詳細的設定可以查看 &lt;a href=&#34;https://keras.io/api/layers/core_layers/dense/&#34;&gt;Keras 手冊&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;卷積層&lt;/h3&gt;
&lt;hr&gt;
&lt;p&gt;  若要建構一個 DNN ，卷積層是必須的，與全連接層相同的做法，只是呼叫的函式不同而已。&lt;/p&gt;
&lt;p&gt;  在接下來的範例中，輸入張量為 100x100x3 ，經過兩層 50 個卷積核為 3x3 ，Stride 為 2 ，不使用 Padding 的卷積層後，進行 Flatten ，最後再接入向量長度為 10 的輸出層。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;M2.png&#34; alt=&#34;image&#34;&gt;&lt;/p&gt;
&lt;figure class=&#34;highlight python&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; tensorflow &lt;span class=&#34;keyword&#34;&gt;as&lt;/span&gt; tf&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; keras.models &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; Model&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; keras.layers &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; Input,Dense,Conv2D&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; keras &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; backend &lt;span class=&#34;keyword&#34;&gt;as&lt;/span&gt; K&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;function&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title&#34;&gt;SequenceModel&lt;/span&gt;():&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;comment&#34;&gt;# 輸入層&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    model_input = Input(shape=(&lt;span class=&#34;number&#34;&gt;100&lt;/span&gt;,&lt;span class=&#34;number&#34;&gt;100&lt;/span&gt;,&lt;span class=&#34;number&#34;&gt;3&lt;/span&gt;), name=&lt;span class=&#34;string&#34;&gt;&amp;#x27;input&amp;#x27;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;comment&#34;&gt;# 隱藏層 1 &lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    hidden = Conv2D(&lt;span class=&#34;number&#34;&gt;50&lt;/span&gt;, (&lt;span class=&#34;number&#34;&gt;3&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;3&lt;/span&gt;), activation=&lt;span class=&#34;string&#34;&gt;&amp;#x27;relu&amp;#x27;&lt;/span&gt;, padding=&lt;span class=&#34;string&#34;&gt;&amp;#x27;valid&amp;#x27;&lt;/span&gt;,name=&lt;span class=&#34;string&#34;&gt;&amp;#x27;hidden_1&amp;#x27;&lt;/span&gt;)(model_input)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;comment&#34;&gt;# 隱藏層 2 &lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    hidden = Conv2D(&lt;span class=&#34;number&#34;&gt;50&lt;/span&gt;, (&lt;span class=&#34;number&#34;&gt;3&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;3&lt;/span&gt;), activation=&lt;span class=&#34;string&#34;&gt;&amp;#x27;relu&amp;#x27;&lt;/span&gt;, padding=&lt;span class=&#34;string&#34;&gt;&amp;#x27;valid&amp;#x27;&lt;/span&gt;,name=&lt;span class=&#34;string&#34;&gt;&amp;#x27;hidden_2&amp;#x27;&lt;/span&gt;)(model_input)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;comment&#34;&gt;# Flatten&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    Flatten_layer = Flatten(name=&lt;span class=&#34;string&#34;&gt;&amp;#x27;flatten&amp;#x27;&lt;/span&gt;)(hidden)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;comment&#34;&gt;# 輸出層 &lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    model_output = Dense(&lt;span class=&#34;number&#34;&gt;10&lt;/span&gt;, activation=&lt;span class=&#34;string&#34;&gt;&amp;#x27;sigmoid&amp;#x27;&lt;/span&gt;,name=&lt;span class=&#34;string&#34;&gt;&amp;quot;output&amp;quot;&lt;/span&gt;)(Flatten_layer)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    model = Model(inputs=[model_input], outputs=[model_output])&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; model&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;同樣，這只是最基本的應用，若要更進階的使用請詳看 &lt;a href=&#34;https://keras.io/api/layers/convolution_layers/&#34;&gt;Keras 手冊&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;  以上，我們已經知道該怎麼建構卷積層及全連接層，使用這兩者已經可以建構一個影像辨識的應用，像是一開始的 AlexNet 及 VGG 系列都是使用單純的卷積加上全連接層建構而成的，接下來，你可以建構自己的架構嘗試進行影像辨識，可以使用&lt;a href=&#34;http://yann.lecun.com/exdb/mnist/&#34;&gt;手寫辨識 MINST&lt;/a&gt; 或是 &lt;a href=&#34;https://www.kaggle.com/c/dogs-vs-cats&#34;&gt;Kaggle 的 Dogs v.s Cats&lt;/a&gt; 進行練習。&lt;/p&gt;
 ]]></description>
        </item>
        <item>
            <guid isPermalink="true">https://nineko.github.io/2020/07/30/MyPaper/</guid>
            <title>Training Deep Networks with Synthetic Data for Textureless Object Pose Estimation</title>
            <link>https://nineko.github.io/2020/07/30/MyPaper/</link>
            <category>DNN</category>
            <category>Computer Vision</category>
            <category>Pose Estimation</category>
            <pubDate>Thu, 30 Jul 2020 16:22:33 +0800</pubDate>
            <description><![CDATA[ &lt;p&gt;碩士研究成果，不過目前因其他因素，無法公開全文，也不適合作太詳細的說明，還請見諒&lt;br&gt;
最晚公開時間 2025.01&lt;/p&gt;
&lt;h1&gt;論文連結&lt;/h1&gt;  
&lt;p&gt;&lt;a href=&#34;https://drive.google.com/open?id=14RATn-h3gV4wIrBbZ2rxjERyxK64EEQM&#34;&gt;https://drive.google.com/open?id=14RATn-h3gV4wIrBbZ2rxjERyxK64EEQM&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://github.com/Nineko/Deep-Learning_Training-Deep-Networks-with-Synthetic-Data-for-Textureless&#34;&gt;Github Link&lt;/a&gt;&lt;/p&gt;
&lt;h1&gt;簡述&lt;/h1&gt;
&lt;h2&gt;問題定義&lt;/h2&gt;
&lt;p&gt;在這個研究中想要解決在工業應用上因傳統視覺伺服的不足而導入深度學習時，所發生的種種問題。&lt;br&gt;
我們假設視覺系統為一個手眼系統 (左圖)，所以能夠以物體為圓心定義出一個球座標系 (右圖)&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;eyeonhand.png&#34; alt=&#34;image&#34;&gt;&lt;/p&gt;
&lt;p&gt;根據此座標系，在我們的研究中主要考慮三個變量 : In-plane Rotation 、 Theta 、 Phi&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;ThreePara.gif&#34; alt=&#34;image&#34;&gt;&lt;/p&gt;
&lt;h2&gt;CAD Simulator&lt;/h2&gt;
&lt;p&gt;同時為了解決訓練資料取得及標定不易的問題，我們撰寫了使用 OpenGL 並在 QT 上進行開發的 CAD 模型模擬器，詳細可以前往我的 CAD-Simulator 專案 (&lt;a href=&#34;https://github.com/Nineko/CAD-Simulator&#34;&gt;https://github.com/Nineko/CAD-Simulator&lt;/a&gt;)&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;CAD%E6%A8%A1%E5%9E%8B%E7%95%8C%E9%9D%A2.png&#34; alt=&#34;image&#34;&gt;&lt;/p&gt;
&lt;h2&gt;測試結果&lt;/h2&gt;
&lt;p&gt;在本研究中，我們利用前述的模擬器產生訓練資料進行訓練，並以相同的方式產生測試集對三種物體進行測試，每種物體都產生了約 16000 張圖片進行測試&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;class.jpg&#34; alt=&#34;image&#34;&gt;&lt;/p&gt;
&lt;p&gt;測試時分成兩個部分，首先為分辨物體及物體定位的結果 :&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center&#34;&gt;Class&lt;/th&gt;
&lt;th style=&#34;text-align:center&#34;&gt;Mean IoU&lt;/th&gt;
&lt;th style=&#34;text-align:center&#34;&gt;Mean Classification Accuracy&lt;/th&gt;
&lt;th style=&#34;text-align:center&#34;&gt;Center X-Shift Error (By pixel)&lt;/th&gt;
&lt;th style=&#34;text-align:center&#34;&gt;Center Y-Shift Error (By pixel)&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Class 1&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;0.8824&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;0.8284&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;2.3140&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;2.2287&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Class 2&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;0.8592&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;0.8496&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;1.6883&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;1.6435&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Class 3&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;0.9362&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;0.8499&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;1.9301&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;1.6057&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;再來是三個變量的估測結果 :&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center&#34;&gt;Class&lt;/th&gt;
&lt;th style=&#34;text-align:center&#34;&gt;Mean In-plane rotation error(°)&lt;/th&gt;
&lt;th style=&#34;text-align:center&#34;&gt;Mean Theta error(°)&lt;/th&gt;
&lt;th style=&#34;text-align:center&#34;&gt;Mean Phi error(°)&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Class 1&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;2.7461&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;1.3171&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;6.2603&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Class 2&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;3.5969&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;0.8520&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;6.2455&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Class 3&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;4.6340&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;1.0070&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;6.0381&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
 ]]></description>
        </item>
        <item>
            <guid isPermalink="true">https://nineko.github.io/2020/07/30/CAD-Simulator/</guid>
            <title>CAD Simulator</title>
            <link>https://nineko.github.io/2020/07/30/CAD-Simulator/</link>
            <category>QT</category>
            <pubDate>Thu, 30 Jul 2020 13:00:15 +0800</pubDate>
            <description><![CDATA[ &lt;p&gt;讀取.dxf 檔案格式，產生渲染合成影像作訓練資料使用&lt;/p&gt;
&lt;p&gt;[*]Develop in QT5.9&lt;br&gt;
&lt;a href=&#34;https://github.com/Nineko/CAD-Simulator&#34;&gt;Github Link&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;clamp.png&#34; alt=&#34;image&#34;&gt;&lt;/p&gt;
&lt;h1&gt;虛擬相機以球座標系定義&lt;/h1&gt;
&lt;p&gt;物體於圓心，虛擬相機的位置將由 1) 物體與相機距離 &lt;code&gt;r&lt;/code&gt;  2) 天頂角 &lt;code&gt;Theta&lt;/code&gt;  3) 方位角 &lt;code&gt;Phi&lt;/code&gt;  三個參數來設定&lt;br&gt;
&lt;img src=&#34;%E7%90%83%E5%BA%A7%E6%A8%99%E7%B3%BB.png&#34; alt=&#34;image&#34;&gt;&lt;/p&gt;
&lt;h1&gt;整體介面&lt;/h1&gt;
&lt;p&gt;可變參數&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Theta angle&lt;/li&gt;
&lt;li&gt;Phi angle&lt;/li&gt;
&lt;li&gt;In-plane rotate angle&lt;/li&gt;
&lt;li&gt;Camera shift(x/y direction)&lt;/li&gt;
&lt;li&gt;Light direction&lt;/li&gt;
&lt;li&gt;batch process setting&lt;br&gt;
&lt;img src=&#34;CAD_UI.png&#34; alt=&#34;image&#34;&gt;&lt;/li&gt;
&lt;/ul&gt;
 ]]></description>
        </item>
        <item>
            <guid isPermalink="true">https://nineko.github.io/2020/07/30/School-Project-PSO/</guid>
            <title>[School Project] Particle Swarm Optimization</title>
            <link>https://nineko.github.io/2020/07/30/School-Project-PSO/</link>
            <category>QT</category>
            <pubDate>Thu, 30 Jul 2020 12:44:44 +0800</pubDate>
            <description><![CDATA[ &lt;p&gt;This program simulates the process which finding the best solution of the Ackley function with particle swarm optimization method&lt;/p&gt;
&lt;p&gt;[*]Develop in qt5.9&lt;br&gt;
&lt;a href=&#34;https://github.com/Nineko/School-Project_Particle-Swarm-Optimization&#34;&gt;Github Link&lt;/a&gt;&lt;/p&gt;
&lt;h1&gt;Object function : Ackley function&lt;/h1&gt;
&lt;p&gt;&lt;img src=&#34;equ.png&#34; alt=&#34;image&#34;&gt;&lt;br&gt;
&lt;img src=&#34;Demo.gif&#34; alt=&#34;image&#34;&gt;&lt;/p&gt;
&lt;h1&gt;Configures&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;The number of partical : (Dedault) 30&lt;/li&gt;
&lt;li&gt;Inertia weight : (Dedault) 0.5&lt;/li&gt;
&lt;li&gt;Personal influence : (Dedault) 0.5&lt;/li&gt;
&lt;li&gt;Social influence : (Dedault) 0.5&lt;/li&gt;
&lt;li&gt;Group size : (Dedault) 10&lt;/li&gt;
&lt;li&gt;Termination condition : (Dedault) 0.000001&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;config.png&#34; alt=&#34;image&#34;&gt;&lt;/p&gt;
 ]]></description>
        </item>
        <item>
            <guid isPermalink="true">https://nineko.github.io/2020/07/30/School-Project-Genetic-Algorithm/</guid>
            <title>[School Project] Genetic Algorithm</title>
            <link>https://nineko.github.io/2020/07/30/School-Project-Genetic-Algorithm/</link>
            <category>QT</category>
            <pubDate>Thu, 30 Jul 2020 11:20:36 +0800</pubDate>
            <description><![CDATA[ &lt;p&gt;This program simulates the process which finding the best solution of the Ackley function with genetic algorithm&lt;/p&gt;
&lt;p&gt;[*]Develop in qt5.9&lt;br&gt;
&lt;a href=&#34;https://github.com/Nineko/School-Project_Genetic-Algorithm&#34;&gt;Github Link&lt;/a&gt;&lt;/p&gt;
&lt;h1&gt;Object function : Ackley function&lt;/h1&gt;
&lt;p&gt;&lt;img src=&#34;equ.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;h1&gt;Configures&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;Initial population size: (Dedault) 50&lt;/li&gt;
&lt;li&gt;Probability of performing crossover : (Dedault) 1.0&lt;/li&gt;
&lt;li&gt;Probability of mutation : (Dedault) 0.5&lt;/li&gt;
&lt;li&gt;Decode mode : binary / real&lt;/li&gt;
&lt;li&gt;Crossover mode : single / double / multiple&lt;/li&gt;
&lt;li&gt;Pooling size : (Dedault) 40&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;conf.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
 ]]></description>
        </item>
    </channel>
</rss>
