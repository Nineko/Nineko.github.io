<?xml version="1.0"?>
<rss version="2.0">
    <channel>
        <title>Nineko&#39;s Blog</title>
        <link>https://nineko.github.io</link>
        <description></description>
        <language>zh-TW</language>
        <pubDate>Wed, 05 Aug 2020 15:10:33 +0800</pubDate>
        <lastBuildDate>Wed, 05 Aug 2020 15:10:33 +0800</lastBuildDate>
        <category>DNN</category>
        <category>QT</category>
        <category>Computer Vision</category>
        <category>Pose Estimation</category>
        <item>
            <guid isPermalink="true">https://nineko.github.io/2020/08/05/Residual-Dense/</guid>
            <title>[筆記]序列模型(3)-Residual &amp; Dense</title>
            <link>https://nineko.github.io/2020/08/05/Residual-Dense/</link>
            <category>DNN</category>
            <pubDate>Wed, 05 Aug 2020 15:10:33 +0800</pubDate>
            <description><![CDATA[ &lt;h1&gt;目錄&lt;/h1&gt;
&lt;p&gt;&lt;a href=&#34;https://nineko.github.io/2020/08/03/Note-BasicSequenceModel/&#34;&gt;基本序列模型&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://nineko.github.io/2020/08/04/Note-Multi-Scale/&#34;&gt;多尺度架構&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Residual &amp;amp; Dense&lt;/strong&gt;&lt;/p&gt;
&lt;h1&gt;Residual&lt;/h1&gt;
&lt;hr&gt;
&lt;p&gt;  Residual 為 &lt;a href=&#34;https://arxiv.org/abs/1512.03385&#34;&gt;ResNet&lt;/a&gt; 中提出的一種架構，中文譯為殘差，其提出的主因是為了解決網路堆疊太深而產生的退化問題，沒錯，網路不是愈深愈好，退化並非 overfitting ，而是誤差確實的提高，這在 ResNet 的論文中有詳細的說明，其實驗證明若只是單純的堆疊網路並不會都是帶來正向的結果。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;M1.png&#34; alt=&#34;image&#34;&gt;&lt;/p&gt;
&lt;p&gt;  為了解決這種情形，殘差的概念被提出，殘差的想法為 ── 本來神經網路學習的過程可以看成找尋一個適當的函式來滿足你的輸入及輸出，假設輸入為 &lt;code&gt;x&lt;/code&gt; ，想要學習的函數為 &lt;code&gt;H(x)&lt;/code&gt; ，那我們今天修改下學習的目標，從 &lt;code&gt;H(x)&lt;/code&gt;  改成 &lt;code&gt;H(x)-x&lt;/code&gt; ，並假設新的目標函式為 &lt;code&gt;F(x)&lt;/code&gt; ，那麼我們可以列出式子 :  &lt;code&gt;F(x)=H(x)-x&lt;/code&gt; ，移項後就變成 &lt;code&gt;F(x)+x=H(x)&lt;/code&gt; ，也就是我們可以利用訓練 &lt;code&gt;F(x)+x&lt;/code&gt;  可以跟原本的 &lt;code&gt;H(x)&lt;/code&gt;  視為等價。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;M2.png&#34; alt=&#34;image&#34;&gt;&lt;/p&gt;
&lt;p&gt;  那麼為甚麼這麼做可以解決網路太深的退化問題呢？若依照論文的解釋，它們認為要找出 &lt;code&gt;F(x)&lt;/code&gt;  的最優解會比 &lt;code&gt;H(x)&lt;/code&gt;  來得容易，因為 &lt;code&gt;F(x)&lt;/code&gt;  是針對誤差的誤差 (感覺好繞) 進行最佳化，所以對於變化更加的敏感，而且就算訓練不好，因為還有本來的 &lt;code&gt;x&lt;/code&gt; ，所以不會太影響本來的結果；&lt;/p&gt;
&lt;p&gt;若上述你已可以理解，那麼非常好，不過這邊還有我依照自己理解的白話解釋，我從特徵角度著手，隨著網路逐層加深，或許有些有用的，但是權重不怎麼高的特徵會被磨滅、被覆蓋等情形發生，表現在結果上便是誤差的提高，也就是退化的真相，殘差架構將前面找出的特徵整組加入目前所計算的特徵上，這意味著不需要擔心這層訓練走歪太多，再不濟還有前一層的結果作為一個基準，以上是我對殘差架構的一點說明及理解，若還是不太清楚，那麼開始動手實做看看，或許你可以找出你自己的理解方式，接下來將會說明該如何實做一個簡單的殘差區塊。&lt;/p&gt;
&lt;figure class=&#34;highlight python&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; tensorflow &lt;span class=&#34;keyword&#34;&gt;as&lt;/span&gt; tf&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; keras &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; backend &lt;span class=&#34;keyword&#34;&gt;as&lt;/span&gt; K&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; keras.models &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; Model&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; keras.layers &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; Conv2D,Input,Add,Activation&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;function&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title&#34;&gt;ResidualBlock&lt;/span&gt;():&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;comment&#34;&gt;# 輸入層&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    model_input = Input(shape=(&lt;span class=&#34;number&#34;&gt;15&lt;/span&gt;,&lt;span class=&#34;number&#34;&gt;15&lt;/span&gt;,&lt;span class=&#34;number&#34;&gt;3&lt;/span&gt;), name=&lt;span class=&#34;string&#34;&gt;&amp;#x27;input&amp;#x27;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;comment&#34;&gt;#  1x1 卷積層&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    conv1 = Conv2D(&lt;span class=&#34;number&#34;&gt;10&lt;/span&gt;, (&lt;span class=&#34;number&#34;&gt;3&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;3&lt;/span&gt;), activation=&lt;span class=&#34;string&#34;&gt;&amp;#x27;relu&amp;#x27;&lt;/span&gt;, padding=&lt;span class=&#34;string&#34;&gt;&amp;#x27;same&amp;#x27;&lt;/span&gt; ,name=&lt;span class=&#34;string&#34;&gt;&amp;#x27;Conv_1&amp;#x27;&lt;/span&gt;)(model_input)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;comment&#34;&gt;#  3x3 卷積層&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    conv2 = Conv2D(&lt;span class=&#34;number&#34;&gt;20&lt;/span&gt;, (&lt;span class=&#34;number&#34;&gt;3&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;3&lt;/span&gt;), activation=&lt;span class=&#34;string&#34;&gt;&amp;#x27;relu&amp;#x27;&lt;/span&gt;, padding=&lt;span class=&#34;string&#34;&gt;&amp;#x27;same&amp;#x27;&lt;/span&gt; ,name=&lt;span class=&#34;string&#34;&gt;&amp;#x27;Conv_2&amp;#x27;&lt;/span&gt;)(conv1)  &lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;comment&#34;&gt;#  5x5 卷積層&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    conv3 = Conv2D(&lt;span class=&#34;number&#34;&gt;10&lt;/span&gt;, (&lt;span class=&#34;number&#34;&gt;3&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;3&lt;/span&gt;), activation=&lt;span class=&#34;string&#34;&gt;&amp;#x27;relu&amp;#x27;&lt;/span&gt;, padding=&lt;span class=&#34;string&#34;&gt;&amp;#x27;same&amp;#x27;&lt;/span&gt; ,name=&lt;span class=&#34;string&#34;&gt;&amp;#x27;Conv_3&amp;#x27;&lt;/span&gt;)(conv2)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;comment&#34;&gt;# 輸出層 - 進行 concatenate&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    model_output= Add([conv1, conv3] ,name=&lt;span class=&#34;string&#34;&gt;&amp;#x27;output&amp;#x27;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    model_output = Activation(&lt;span class=&#34;string&#34;&gt;&amp;#x27;relu&amp;#x27;&lt;/span&gt;)(model_output)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    model = Model(inputs=[model_input], outputs=[model_output])&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; model&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;&lt;img src=&#34;M3.png&#34; alt=&#34;image&#34;&gt;&lt;/p&gt;
&lt;p&gt;  建構起來非常的簡單，範例中 &lt;code&gt;model_input&lt;/code&gt;  經過一層 &lt;code&gt;conv1&lt;/code&gt;  後進入 Residual block，因為我們需要將 &lt;code&gt;conv1&lt;/code&gt;  的結果向後傳遞與 Residual block 的輸出相加，所以在 block 的輸出層時 (範例中的 &lt;code&gt;conv3&lt;/code&gt; )，要注意將維度調整為與 &lt;code&gt;conv1&lt;/code&gt;  相同，否則無法正確相加。&lt;/p&gt;
&lt;p&gt;相加的方法為使用 &lt;code&gt;keras.layers&lt;/code&gt;  中的 &lt;code&gt;Add&lt;/code&gt;  類別&lt;/p&gt;
&lt;figure class=&#34;highlight python&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;tf.keras.layers.Add(**kwargs)&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;詳細的說明可以參照 &lt;a href=&#34;https://keras.io/api/layers/merging_layers/concatenate/&#34;&gt;Keras 手冊&lt;/a&gt;&lt;/p&gt;
&lt;h1&gt;Dense&lt;/h1&gt;
&lt;hr&gt;
&lt;p&gt;  Dense 方法則是可以在 &lt;a href=&#34;https://arxiv.org/abs/1608.06993&#34;&gt;DenseNet&lt;/a&gt; 中看到，其想法與殘差類似，但是不像殘差使用相加的操作，Dense 方法中採用了 concatenate 的方式，並且操作的不只單單前一層，而是前面的所有層，這大大的增強了所有可能的特徵，並且因其採用 concatenate 的方式，所以特徵能夠完全的保留並參予計算。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;M4.png&#34; alt=&#34;image&#34;&gt;&lt;/p&gt;
&lt;p&gt;  雖然看起來很複雜，但是其實非常好理解，與殘差的想法相同，為了不讓網路在計算時失去有用的特徵，所以將先前找到的特徵加入以防消失，只不過 Dense 方法做得更絕而已，它乾脆一股腦兒的把之前計算的通通併在一塊兒，連同這層的輸出一併餵入下一層。&lt;/p&gt;
&lt;p&gt;  已經有了殘差的概念，理解 Dense 應該不會太困難，接下來就直接進行實做，在範例中，只會實做滿足 Dense 概念的小區塊，若需要看它實際的應用成果，建議查看 &lt;a href=&#34;https://arxiv.org/abs/1608.06993&#34;&gt;DenseNet&lt;/a&gt; ，論文中除了 Dense 架構外，還有著很多特別有趣的操作。&lt;/p&gt;
&lt;figure class=&#34;highlight python&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; tensorflow &lt;span class=&#34;keyword&#34;&gt;as&lt;/span&gt; tf&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; keras &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; backend &lt;span class=&#34;keyword&#34;&gt;as&lt;/span&gt; K&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; keras.models &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; Model&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; keras.layers &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; Conv2D,Input,concatenate,Activation&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;function&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title&#34;&gt;DenseBlock&lt;/span&gt;():&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;comment&#34;&gt;# 輸入層&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    model_input = Input(shape=(&lt;span class=&#34;number&#34;&gt;15&lt;/span&gt;,&lt;span class=&#34;number&#34;&gt;15&lt;/span&gt;,&lt;span class=&#34;number&#34;&gt;3&lt;/span&gt;), name=&lt;span class=&#34;string&#34;&gt;&amp;#x27;input&amp;#x27;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;comment&#34;&gt;#  卷積層 1&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    conv1 = Conv2D(&lt;span class=&#34;number&#34;&gt;10&lt;/span&gt;, (&lt;span class=&#34;number&#34;&gt;3&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;3&lt;/span&gt;), activation=&lt;span class=&#34;string&#34;&gt;&amp;#x27;relu&amp;#x27;&lt;/span&gt;, padding=&lt;span class=&#34;string&#34;&gt;&amp;#x27;same&amp;#x27;&lt;/span&gt; ,name=&lt;span class=&#34;string&#34;&gt;&amp;#x27;Conv_1&amp;#x27;&lt;/span&gt;)(model_input)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;comment&#34;&gt;#  將前一層的輸出與這層的結果合併&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    concat1 = concatenate([model_input, conv1] , axis=&lt;span class=&#34;number&#34;&gt;3&lt;/span&gt;,name=&lt;span class=&#34;string&#34;&gt;&amp;#x27;Concat_1&amp;#x27;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;comment&#34;&gt;#  卷積層 2&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    conv2 = Conv2D(&lt;span class=&#34;number&#34;&gt;20&lt;/span&gt;, (&lt;span class=&#34;number&#34;&gt;3&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;3&lt;/span&gt;), activation=&lt;span class=&#34;string&#34;&gt;&amp;#x27;relu&amp;#x27;&lt;/span&gt;, padding=&lt;span class=&#34;string&#34;&gt;&amp;#x27;same&amp;#x27;&lt;/span&gt; ,name=&lt;span class=&#34;string&#34;&gt;&amp;#x27;Conv_2&amp;#x27;&lt;/span&gt;)(concat1)  &lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;comment&#34;&gt;#  將前面兩層的輸出與這層的結果合併&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    concat2 = concatenate([concat1, conv2] , axis=&lt;span class=&#34;number&#34;&gt;3&lt;/span&gt;,name=&lt;span class=&#34;string&#34;&gt;&amp;#x27;Concat_2&amp;#x27;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;comment&#34;&gt;#  卷積層 3&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    conv3 = Conv2D(&lt;span class=&#34;number&#34;&gt;10&lt;/span&gt;, (&lt;span class=&#34;number&#34;&gt;3&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;3&lt;/span&gt;), activation=&lt;span class=&#34;string&#34;&gt;&amp;#x27;relu&amp;#x27;&lt;/span&gt;, padding=&lt;span class=&#34;string&#34;&gt;&amp;#x27;same&amp;#x27;&lt;/span&gt; ,name=&lt;span class=&#34;string&#34;&gt;&amp;#x27;Conv_3&amp;#x27;&lt;/span&gt;)(concat2)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;comment&#34;&gt;# 輸出層 &lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    model_output= concatenate([concat2, conv3] , axis=&lt;span class=&#34;number&#34;&gt;3&lt;/span&gt;,name=&lt;span class=&#34;string&#34;&gt;&amp;#x27;Concat_3&amp;#x27;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    model = Model(inputs=[model_input], outputs=[model_output])&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; model&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;&lt;img src=&#34;M5.png&#34; alt=&#34;image&#34;&gt;&lt;/p&gt;
&lt;p&gt;  可以看到範例中每個餵入下層卷積的輸入都是由前面層所合併的，但是別看深度愈來愈多，好像會很花計算資源，但其實以生成特徵的花費來看，同樣一個 256 維的特徵，一個是直接計算出 256 維，一個是由前面 4 層的 64 維組裝起來，差異就出來了，使用這種方法，反而可以減少產生特徵的花費，並可以保留前面的特徵，防止其退化，這種操作還是很巧妙的。&lt;/p&gt;
&lt;p&gt;  至此，我們已經說明了序列模型的建構以及兩種架構技巧，對於很多應用來說，這些已經足夠應付，不過該如何變化，還是需要自行去好好研究，甚至模型架構也只是深度學習的一環而已，還有很重要的訓練資料及損失函數等等部分都是進行一個深度學習專案需要考慮的事情，深度學習的坑是很深的，並不是單純的把資料丟進去讓它慢慢跑就好，所以，學無止盡，既然踏入了深度學習這個巨坑，只能持續的接受更多的知識了。&lt;/p&gt;
 ]]></description>
        </item>
        <item>
            <guid isPermalink="true">https://nineko.github.io/2020/08/04/Note-Multi-Scale/</guid>
            <title>[筆記]序列模型(2)-多尺度架構</title>
            <link>https://nineko.github.io/2020/08/04/Note-Multi-Scale/</link>
            <category>DNN</category>
            <pubDate>Tue, 04 Aug 2020 11:15:06 +0800</pubDate>
            <description><![CDATA[ &lt;h1&gt;目錄&lt;/h1&gt;
&lt;p&gt;&lt;a href=&#34;https://nineko.github.io/2020/08/03/Note-BasicSequenceModel/&#34;&gt;基本序列模型&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;多尺度架構&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://nineko.github.io/2020/08/05/Residual-Dense/&#34;&gt;Residual &amp;amp; Dense&lt;/a&gt;&lt;/p&gt;
&lt;h1&gt;多尺度架構&lt;/h1&gt;
&lt;hr&gt;
&lt;p&gt;  多尺度架構能夠在 GoogLeNet 中的 Inception 架構中廣泛看到，其概念想法為利用不同卷積核大小的卷積層來給予網路更多的選擇去擷取適當的特徵，在架構上，我們能夠把多尺度架構分成兩個步驟──分散及匯集；分散指的是將輸入分散至不同大小卷積核的卷積層，匯集則是將不同卷積層的結果重新組裝成一個張量，所以在進行卷積計算時，會利用 Padding 來確保輸出張量的長寬是一致的，圖解的話像是這種感覺。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;M1.png&#34; alt=&#34;image&#34;&gt;&lt;/p&gt;
&lt;p&gt;  可以看到為了進行多尺度的計算，我們無法去操作特徵圖的長寬，這意味著龐大的參數計算，為了緩和計算負擔，我們可以利用多次卷積降低兩維的大小，將資訊累積在深度上，多尺度計算時也可以利用 1x1 的卷積核來降低深度維度，使用這些技巧來建構多尺度架構，在結果與參數使用量上取得適當的平衡吧。&lt;/p&gt;
&lt;p&gt;接下來將會用簡單的範例來示範如何建構一個多尺度架構。&lt;/p&gt;
&lt;figure class=&#34;highlight python&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; tensorflow &lt;span class=&#34;keyword&#34;&gt;as&lt;/span&gt; tf&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; keras &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; backend &lt;span class=&#34;keyword&#34;&gt;as&lt;/span&gt; K&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; keras.models &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; Model&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; keras.layers &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; Conv2D,Input,concatenate&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;function&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title&#34;&gt;MultiScaleModel&lt;/span&gt;():&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;comment&#34;&gt;# 輸入層&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    model_input = Input(shape=(&lt;span class=&#34;number&#34;&gt;15&lt;/span&gt;,&lt;span class=&#34;number&#34;&gt;15&lt;/span&gt;,&lt;span class=&#34;number&#34;&gt;3&lt;/span&gt;), name=&lt;span class=&#34;string&#34;&gt;&amp;#x27;input&amp;#x27;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;comment&#34;&gt;#  1x1 卷積層&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    conv1 = Conv2D(&lt;span class=&#34;number&#34;&gt;10&lt;/span&gt;, (&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;), activation=&lt;span class=&#34;string&#34;&gt;&amp;#x27;relu&amp;#x27;&lt;/span&gt;, padding=&lt;span class=&#34;string&#34;&gt;&amp;#x27;same&amp;#x27;&lt;/span&gt; ,name=&lt;span class=&#34;string&#34;&gt;&amp;#x27;Conv_1_1&amp;#x27;&lt;/span&gt;)(model_input)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;comment&#34;&gt;#  3x3 卷積層&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    conv3 = Conv2D(&lt;span class=&#34;number&#34;&gt;20&lt;/span&gt;, (&lt;span class=&#34;number&#34;&gt;3&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;3&lt;/span&gt;), activation=&lt;span class=&#34;string&#34;&gt;&amp;#x27;relu&amp;#x27;&lt;/span&gt;, padding=&lt;span class=&#34;string&#34;&gt;&amp;#x27;same&amp;#x27;&lt;/span&gt; ,name=&lt;span class=&#34;string&#34;&gt;&amp;#x27;Conv_3_3&amp;#x27;&lt;/span&gt;)(model_input)  &lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;comment&#34;&gt;#  5x5 卷積層&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    conv5 = Conv2D(&lt;span class=&#34;number&#34;&gt;30&lt;/span&gt;, (&lt;span class=&#34;number&#34;&gt;5&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;5&lt;/span&gt;), activation=&lt;span class=&#34;string&#34;&gt;&amp;#x27;relu&amp;#x27;&lt;/span&gt;, padding=&lt;span class=&#34;string&#34;&gt;&amp;#x27;same&amp;#x27;&lt;/span&gt; ,name=&lt;span class=&#34;string&#34;&gt;&amp;#x27;Conv_5_5&amp;#x27;&lt;/span&gt;)(model_input)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;comment&#34;&gt;# 輸出層 - 進行 concatenate&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    model_output= concatenate([conv1, conv3, conv5] , axis=&lt;span class=&#34;number&#34;&gt;3&lt;/span&gt;,name=&lt;span class=&#34;string&#34;&gt;&amp;#x27;output&amp;#x27;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    model = Model(inputs=[model_input], outputs=[model_output])&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; model&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;使用 &lt;code&gt;model.summary()&lt;/code&gt;  可以更清楚的看到架構。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;M2.png&#34; alt=&#34;image&#34;&gt;&lt;/p&gt;
&lt;p&gt;這裡值得一提的是，在進行 concatenate 時，需要指定接合的維度。&lt;/p&gt;
&lt;figure class=&#34;highlight python&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;tf.keras.layers.Concatenate(axis=&lt;span class=&#34;number&#34;&gt;-1&lt;/span&gt;, **kwargs)&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;在這裡因為我們的卷積層輸出為 (None,15,15,10) 、 (None,15,15,20) 、 (None,15,15,30) ，需要接合的為第三維度，所以需要設定 &lt;code&gt;axis=3&lt;/code&gt; ，若想了解更多資訊，可以參考 &lt;a href=&#34;https://keras.io/api/layers/merging_layers/concatenate/&#34;&gt;Keras 手冊&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;  在範例中，我們只建構了一層最簡單的多尺度架構，在使用上這樣的一層只是一個 Block ，利用堆疊這些 Block 如同在建構一般卷積層一般，更深的層數意味著更複雜的特徵組合，然而比起普通卷積，多尺度的一層中包含了不同卷積核的特徵，多層疊加下會得到更複雜的特徵，給予我們設計網路架構時多了一種思路。&lt;/p&gt;
 ]]></description>
        </item>
        <item>
            <guid isPermalink="true">https://nineko.github.io/2020/08/03/Note-BasicSequenceModel/</guid>
            <title>[筆記]序列模型(1)-基本序列模型</title>
            <link>https://nineko.github.io/2020/08/03/Note-BasicSequenceModel/</link>
            <category>DNN</category>
            <pubDate>Mon, 03 Aug 2020 15:55:22 +0800</pubDate>
            <description><![CDATA[ &lt;h1&gt;目錄&lt;/h1&gt;
&lt;p&gt;&lt;strong&gt;基本序列模型&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://nineko.github.io/2020/08/04/Note-Multi-Scale/&#34;&gt;多尺度架構&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://nineko.github.io/2020/08/05/Residual-Dense/&#34;&gt;Residual &amp;amp; Dense&lt;/a&gt;&lt;/p&gt;
&lt;h1&gt;基本序列模型&lt;/h1&gt;
&lt;hr&gt;
&lt;p&gt;  序列模型為建構深度學習網路時最直觀也最簡便的方式，在大多數時候，序列模型往往能夠讓你在解決問題上提供一個初步的解決方案。&lt;/p&gt;
&lt;p&gt;不過儘管它如此單純，依舊值得好好研究，在本篇中將會從最基本的開始說明，也就是沒有任何特別操作，單純一層疊一層的方式來建構深度學習網路。&lt;/p&gt;
&lt;p&gt;這種方式在初期被大量使用，它方便架設，也很容易理解，但是它因簡單的架構，無法處理太過於複雜的特徵，也沒有任何機制去降低計算量，可說是有利有弊。&lt;/p&gt;
&lt;h2&gt;建構&lt;/h2&gt;
&lt;hr&gt;
&lt;h3&gt;全連接層&lt;/h3&gt;
&lt;hr&gt;
&lt;p&gt;在這個筆記裡，範例皆為 Keras 實做版本，Keras 版本為 2.4.3 ，基底 Tensorflow 版本為 2.3.0 。&lt;/p&gt;
&lt;p&gt;假設我們想要建構一個輸入長度為 100 的向量，經過兩層輸出為 50 的隱藏層後，最後輸出長度為 10 的向量。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;M1.png&#34; alt=&#34;image&#34;&gt;&lt;/p&gt;
&lt;p&gt;在 Keras 中，我們可以使用很簡單的方式來建構一個序列模型。&lt;/p&gt;
&lt;figure class=&#34;highlight python&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; tensorflow &lt;span class=&#34;keyword&#34;&gt;as&lt;/span&gt; tf&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; keras.models &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; Model&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; keras.layers &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; Input,Dense&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; keras &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; backend &lt;span class=&#34;keyword&#34;&gt;as&lt;/span&gt; K&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;function&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title&#34;&gt;SequenceModel&lt;/span&gt;():&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;comment&#34;&gt;# 輸入層&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    model_input = Input(shape=(&lt;span class=&#34;number&#34;&gt;100&lt;/span&gt;), name=&lt;span class=&#34;string&#34;&gt;&amp;#x27;input&amp;#x27;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;comment&#34;&gt;# 隱藏層 1 &lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    hidden = Dense(&lt;span class=&#34;number&#34;&gt;50&lt;/span&gt;, activation=&lt;span class=&#34;string&#34;&gt;&amp;#x27;sigmoid&amp;#x27;&lt;/span&gt;,name=&lt;span class=&#34;string&#34;&gt;&amp;quot;hidden_1&amp;quot;&lt;/span&gt;)(model_input)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;comment&#34;&gt;# 隱藏層 2 &lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    hidden = Dense(&lt;span class=&#34;number&#34;&gt;50&lt;/span&gt;, activation=&lt;span class=&#34;string&#34;&gt;&amp;#x27;sigmoid&amp;#x27;&lt;/span&gt;,name=&lt;span class=&#34;string&#34;&gt;&amp;quot;hidden_2&amp;quot;&lt;/span&gt;)(hidden)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;comment&#34;&gt;# 輸出層 &lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    model_output = Dense(&lt;span class=&#34;number&#34;&gt;10&lt;/span&gt;, activation=&lt;span class=&#34;string&#34;&gt;&amp;#x27;sigmoid&amp;#x27;&lt;/span&gt;,name=&lt;span class=&#34;string&#34;&gt;&amp;quot;output&amp;quot;&lt;/span&gt;)(hidden)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    model = Model(inputs=[model_input], outputs=[model_output])&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; model&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;  可以看到由 Keras 建構只需要專心建構網路的架構，而不需要做 Weight 及 Bias 的數量及初始化定義，它會以預設的參數進行建構，若要修改也可以帶入引數進行設定。&lt;/p&gt;
&lt;figure class=&#34;highlight python&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;keras.layers.Dense(units, &lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;                   activation=&lt;span class=&#34;literal&#34;&gt;None&lt;/span&gt;, &lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;                   use_bias=&lt;span class=&#34;literal&#34;&gt;True&lt;/span&gt;, &lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;                   kernel_initializer=&lt;span class=&#34;string&#34;&gt;&amp;#x27;glorot_uniform&amp;#x27;&lt;/span&gt;, bias_initializer=&lt;span class=&#34;string&#34;&gt;&amp;#x27;zeros&amp;#x27;&lt;/span&gt;, &lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;                   kernel_regularizer=&lt;span class=&#34;literal&#34;&gt;None&lt;/span&gt;, &lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;                   bias_regularizer=&lt;span class=&#34;literal&#34;&gt;None&lt;/span&gt;, &lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;                   activity_regularizer=&lt;span class=&#34;literal&#34;&gt;None&lt;/span&gt;, &lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;                   kernel_constraint=&lt;span class=&#34;literal&#34;&gt;None&lt;/span&gt;, &lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;                   bias_constraint=&lt;span class=&#34;literal&#34;&gt;None&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;若要了解更詳細的設定可以查看 &lt;a href=&#34;https://keras.io/api/layers/core_layers/dense/&#34;&gt;Keras 手冊&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;卷積層&lt;/h3&gt;
&lt;hr&gt;
&lt;p&gt;  若要建構一個 DNN ，卷積層是必須的，與全連接層相同的做法，只是呼叫的函式不同而已。&lt;/p&gt;
&lt;p&gt;  在接下來的範例中，輸入張量為 100x100x3 ，經過兩層 50 個卷積核為 3x3 ，Stride 為 2 ，不使用 Padding 的卷積層後，進行 Flatten ，最後再接入向量長度為 10 的輸出層。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;M2.png&#34; alt=&#34;image&#34;&gt;&lt;/p&gt;
&lt;figure class=&#34;highlight python&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; tensorflow &lt;span class=&#34;keyword&#34;&gt;as&lt;/span&gt; tf&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; keras.models &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; Model&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; keras.layers &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; Input,Dense,Conv2D&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; keras &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; backend &lt;span class=&#34;keyword&#34;&gt;as&lt;/span&gt; K&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;function&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title&#34;&gt;SequenceModel&lt;/span&gt;():&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;comment&#34;&gt;# 輸入層&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    model_input = Input(shape=(&lt;span class=&#34;number&#34;&gt;100&lt;/span&gt;,&lt;span class=&#34;number&#34;&gt;100&lt;/span&gt;,&lt;span class=&#34;number&#34;&gt;3&lt;/span&gt;), name=&lt;span class=&#34;string&#34;&gt;&amp;#x27;input&amp;#x27;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;comment&#34;&gt;# 隱藏層 1 &lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    hidden = Conv2D(&lt;span class=&#34;number&#34;&gt;50&lt;/span&gt;, (&lt;span class=&#34;number&#34;&gt;3&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;3&lt;/span&gt;), activation=&lt;span class=&#34;string&#34;&gt;&amp;#x27;relu&amp;#x27;&lt;/span&gt;, padding=&lt;span class=&#34;string&#34;&gt;&amp;#x27;valid&amp;#x27;&lt;/span&gt;,name=&lt;span class=&#34;string&#34;&gt;&amp;#x27;hidden_1&amp;#x27;&lt;/span&gt;)(model_input)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;comment&#34;&gt;# 隱藏層 2 &lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    hidden = Conv2D(&lt;span class=&#34;number&#34;&gt;50&lt;/span&gt;, (&lt;span class=&#34;number&#34;&gt;3&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;3&lt;/span&gt;), activation=&lt;span class=&#34;string&#34;&gt;&amp;#x27;relu&amp;#x27;&lt;/span&gt;, padding=&lt;span class=&#34;string&#34;&gt;&amp;#x27;valid&amp;#x27;&lt;/span&gt;,name=&lt;span class=&#34;string&#34;&gt;&amp;#x27;hidden_2&amp;#x27;&lt;/span&gt;)(model_input)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;comment&#34;&gt;# Flatten&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    Flatten_layer = Flatten(name=&lt;span class=&#34;string&#34;&gt;&amp;#x27;flatten&amp;#x27;&lt;/span&gt;)(hidden)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;comment&#34;&gt;# 輸出層 &lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    model_output = Dense(&lt;span class=&#34;number&#34;&gt;10&lt;/span&gt;, activation=&lt;span class=&#34;string&#34;&gt;&amp;#x27;sigmoid&amp;#x27;&lt;/span&gt;,name=&lt;span class=&#34;string&#34;&gt;&amp;quot;output&amp;quot;&lt;/span&gt;)(Flatten_layer)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    model = Model(inputs=[model_input], outputs=[model_output])&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; model&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;同樣，這只是最基本的應用，若要更進階的使用請詳看 &lt;a href=&#34;https://keras.io/api/layers/convolution_layers/&#34;&gt;Keras 手冊&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;  以上，我們已經知道該怎麼建構卷積層及全連接層，使用這兩者已經可以建構一個影像辨識的應用，像是一開始的 AlexNet 及 VGG 系列都是使用單純的卷積加上全連接層建構而成的，接下來，你可以建構自己的架構嘗試進行影像辨識，可以使用&lt;a href=&#34;http://yann.lecun.com/exdb/mnist/&#34;&gt;手寫辨識 MINST&lt;/a&gt; 或是 &lt;a href=&#34;https://www.kaggle.com/c/dogs-vs-cats&#34;&gt;Kaggle 的 Dogs v.s Cats&lt;/a&gt; 進行練習。&lt;/p&gt;
 ]]></description>
        </item>
        <item>
            <guid isPermalink="true">https://nineko.github.io/2020/07/30/MyPaper/</guid>
            <title>Training Deep Networks with Synthetic Data for Textureless Object Pose Estimation</title>
            <link>https://nineko.github.io/2020/07/30/MyPaper/</link>
            <category>DNN</category>
            <category>Computer Vision</category>
            <category>Pose Estimation</category>
            <pubDate>Thu, 30 Jul 2020 16:22:33 +0800</pubDate>
            <description><![CDATA[ &lt;p&gt;  碩士研究成果，不過目前因其他因素，無法公開全文，也不適合作太詳細的說明，還請見諒&lt;br&gt;
最晚公開時間 2025.01&lt;/p&gt;
&lt;h1&gt;論文連結&lt;/h1&gt;
&lt;hr&gt;
&lt;p&gt;&lt;a href=&#34;https://drive.google.com/open?id=14RATn-h3gV4wIrBbZ2rxjERyxK64EEQM&#34;&gt;https://drive.google.com/open?id=14RATn-h3gV4wIrBbZ2rxjERyxK64EEQM&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://github.com/Nineko/Deep-Learning_Training-Deep-Networks-with-Synthetic-Data-for-Textureless&#34;&gt;Github Link&lt;/a&gt;&lt;/p&gt;
&lt;h1&gt;簡述&lt;/h1&gt;
&lt;hr&gt;
&lt;h2&gt;問題定義&lt;/h2&gt;
&lt;hr&gt;
&lt;p&gt;  在這個研究中想要解決在工業應用上因傳統視覺伺服的不足而導入深度學習時，所發生的種種問題，我們專注研究在機器手臂抓取物體的這個動作上，我們主要研究 :&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;全數利用合成影像進行訓練對於實際應用的可行性&lt;/li&gt;
&lt;li&gt;異質編碼器架構對於無紋理目標檢測的優勢&lt;/li&gt;
&lt;li&gt;多階段式預測的必要性&lt;/li&gt;
&lt;li&gt;整體系統的實際可行性&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;我們假設視覺系統為一個手眼系統 (左圖)，所以能夠以物體為圓心定義出一個球座標系 (右圖)&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;eyeonhand.png&#34; alt=&#34;image&#34;&gt;&lt;/p&gt;
&lt;p&gt;  根據此座標系，在我們的研究中主要考慮三個變量 : In-plane Rotation 、 Theta 、 Phi&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;ThreePara.gif&#34; alt=&#34;image&#34;&gt;&lt;/p&gt;
&lt;h2&gt;CAD Simulator&lt;/h2&gt;
&lt;p&gt;  同時為了解決訓練資料取得及標定不易的問題，我們撰寫了使用 OpenGL 並在 QT 上進行開發的 CAD 模型模擬器，詳細可以前往我的 CAD-Simulator 專案 (&lt;a href=&#34;https://github.com/Nineko/CAD-Simulator&#34;&gt;https://github.com/Nineko/CAD-Simulator&lt;/a&gt;)&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;CAD%E6%A8%A1%E5%9E%8B%E7%95%8C%E9%9D%A2.png&#34; alt=&#34;image&#34;&gt;&lt;/p&gt;
&lt;h2&gt;測試結果&lt;/h2&gt;
&lt;hr&gt;
&lt;p&gt;  在本研究中，我們利用前述的模擬器產生訓練資料進行訓練，並以相同的方式產生測試集對三種物體進行測試，每種物體都產生了約 16000 張圖片進行測試&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;class.jpg&#34; alt=&#34;image&#34;&gt;&lt;/p&gt;
&lt;p&gt;  測試時分成兩個部分，首先為分辨物體及物體定位的結果 :&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center&#34;&gt;Class&lt;/th&gt;
&lt;th style=&#34;text-align:center&#34;&gt;Mean IoU&lt;/th&gt;
&lt;th style=&#34;text-align:center&#34;&gt;Mean Classification Accuracy&lt;/th&gt;
&lt;th style=&#34;text-align:center&#34;&gt;Center X-Shift Error (By pixel)&lt;/th&gt;
&lt;th style=&#34;text-align:center&#34;&gt;Center Y-Shift Error (By pixel)&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Class 1&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;0.8824&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;0.8284&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;2.3140&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;2.2287&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Class 2&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;0.8592&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;0.8496&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;1.6883&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;1.6435&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Class 3&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;0.9362&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;0.8499&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;1.9301&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;1.6057&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;  再來是三個變量的估測結果 :&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center&#34;&gt;Class&lt;/th&gt;
&lt;th style=&#34;text-align:center&#34;&gt;Mean In-plane rotation error(°)&lt;/th&gt;
&lt;th style=&#34;text-align:center&#34;&gt;Mean Theta error(°)&lt;/th&gt;
&lt;th style=&#34;text-align:center&#34;&gt;Mean Phi error(°)&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Class 1&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;2.7461&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;1.3171&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;6.2603&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Class 2&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;3.5969&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;0.8520&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;6.2455&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Class 3&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;4.6340&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;1.0070&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;6.0381&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
 ]]></description>
        </item>
        <item>
            <guid isPermalink="true">https://nineko.github.io/2020/07/30/CAD-Simulator/</guid>
            <title>CAD Simulator</title>
            <link>https://nineko.github.io/2020/07/30/CAD-Simulator/</link>
            <category>QT</category>
            <pubDate>Thu, 30 Jul 2020 13:00:15 +0800</pubDate>
            <description><![CDATA[ &lt;p&gt;讀取.dxf 檔案格式，產生渲染合成影像作訓練資料使用&lt;/p&gt;
&lt;p&gt;[*]Develop in QT5.9&lt;br&gt;
&lt;a href=&#34;https://github.com/Nineko/CAD-Simulator&#34;&gt;Github Link&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;clamp.png&#34; alt=&#34;image&#34;&gt;&lt;/p&gt;
&lt;h1&gt;虛擬相機以球座標系定義&lt;/h1&gt;
&lt;p&gt;物體於圓心，虛擬相機的位置將由 1) 物體與相機距離 &lt;code&gt;r&lt;/code&gt;  2) 天頂角 &lt;code&gt;Theta&lt;/code&gt;  3) 方位角 &lt;code&gt;Phi&lt;/code&gt;  三個參數來設定&lt;br&gt;
&lt;img src=&#34;%E7%90%83%E5%BA%A7%E6%A8%99%E7%B3%BB.png&#34; alt=&#34;image&#34;&gt;&lt;/p&gt;
&lt;h1&gt;整體介面&lt;/h1&gt;
&lt;p&gt;可變參數&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Theta angle&lt;/li&gt;
&lt;li&gt;Phi angle&lt;/li&gt;
&lt;li&gt;In-plane rotate angle&lt;/li&gt;
&lt;li&gt;Camera shift(x/y direction)&lt;/li&gt;
&lt;li&gt;Light direction&lt;/li&gt;
&lt;li&gt;batch process setting&lt;br&gt;
&lt;img src=&#34;CAD_UI.png&#34; alt=&#34;image&#34;&gt;&lt;/li&gt;
&lt;/ul&gt;
 ]]></description>
        </item>
        <item>
            <guid isPermalink="true">https://nineko.github.io/2020/07/30/School-Project-PSO/</guid>
            <title>[School Project] Particle Swarm Optimization</title>
            <link>https://nineko.github.io/2020/07/30/School-Project-PSO/</link>
            <category>QT</category>
            <pubDate>Thu, 30 Jul 2020 12:44:44 +0800</pubDate>
            <description><![CDATA[ &lt;p&gt;This program simulates the process which finding the best solution of the Ackley function with particle swarm optimization method&lt;/p&gt;
&lt;p&gt;[*]Develop in qt5.9&lt;br&gt;
&lt;a href=&#34;https://github.com/Nineko/School-Project_Particle-Swarm-Optimization&#34;&gt;Github Link&lt;/a&gt;&lt;/p&gt;
&lt;h1&gt;Object function : Ackley function&lt;/h1&gt;
&lt;p&gt;&lt;img src=&#34;equ.png&#34; alt=&#34;image&#34;&gt;&lt;br&gt;
&lt;img src=&#34;Demo.gif&#34; alt=&#34;image&#34;&gt;&lt;/p&gt;
&lt;h1&gt;Configures&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;The number of partical : (Dedault) 30&lt;/li&gt;
&lt;li&gt;Inertia weight : (Dedault) 0.5&lt;/li&gt;
&lt;li&gt;Personal influence : (Dedault) 0.5&lt;/li&gt;
&lt;li&gt;Social influence : (Dedault) 0.5&lt;/li&gt;
&lt;li&gt;Group size : (Dedault) 10&lt;/li&gt;
&lt;li&gt;Termination condition : (Dedault) 0.000001&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;config.png&#34; alt=&#34;image&#34;&gt;&lt;/p&gt;
 ]]></description>
        </item>
        <item>
            <guid isPermalink="true">https://nineko.github.io/2020/07/30/School-Project-Genetic-Algorithm/</guid>
            <title>[School Project] Genetic Algorithm</title>
            <link>https://nineko.github.io/2020/07/30/School-Project-Genetic-Algorithm/</link>
            <category>QT</category>
            <pubDate>Thu, 30 Jul 2020 11:20:36 +0800</pubDate>
            <description><![CDATA[ &lt;p&gt;This program simulates the process which finding the best solution of the Ackley function with genetic algorithm&lt;/p&gt;
&lt;p&gt;[*]Develop in qt5.9&lt;br&gt;
&lt;a href=&#34;https://github.com/Nineko/School-Project_Genetic-Algorithm&#34;&gt;Github Link&lt;/a&gt;&lt;/p&gt;
&lt;h1&gt;Object function : Ackley function&lt;/h1&gt;
&lt;p&gt;&lt;img src=&#34;equ.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;h1&gt;Configures&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;Initial population size: (Dedault) 50&lt;/li&gt;
&lt;li&gt;Probability of performing crossover : (Dedault) 1.0&lt;/li&gt;
&lt;li&gt;Probability of mutation : (Dedault) 0.5&lt;/li&gt;
&lt;li&gt;Decode mode : binary / real&lt;/li&gt;
&lt;li&gt;Crossover mode : single / double / multiple&lt;/li&gt;
&lt;li&gt;Pooling size : (Dedault) 40&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;conf.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
 ]]></description>
        </item>
    </channel>
</rss>
