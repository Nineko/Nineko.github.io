{
    "version": "https://jsonfeed.org/version/1",
    "title": "Nineko's Blog • All posts by \"note\" category",
    "description": "",
    "home_page_url": "https://nineko.github.io",
    "items": [
        {
            "id": "https://nineko.github.io/2020/08/03/Note-BasicSequenceModel/",
            "url": "https://nineko.github.io/2020/08/03/Note-BasicSequenceModel/",
            "title": "[筆記]序列模型(1)-基本序列模型",
            "date_published": "2020-08-03T07:55:22.000Z",
            "content_html": "<h1>目錄</h1>\n<p><strong>基本序列模型</strong></p>\n<p>多尺度架構</p>\n<p>捷徑架構</p>\n<h1>基本序列模型</h1>\n<p>  序列模型為建構深度學習網路時最直觀也最簡便的方式，在大多數時候，序列模型往往能夠讓你在解決問題上提供一個初步的解決方案。</p>\n<p>不過儘管它如此單純，依舊值得好好研究，在本篇中將會從最基本的開始說明，也就是沒有任何特別操作，單純一層疊一層的方式來建構深度學習網路。</p>\n<p>這種方式在初期被大量使用，它方便架設，也很容易理解，但是它因簡單的架構，無法處理太過於複雜的特徵，也沒有任何機制去降低計算量，可說是有利有弊。</p>\n<h2>建構</h2>\n<h3>全連接層</h3>\n<p>在這個筆記裡，範例皆為 Keras 實做版本，Keras 版本為 2.4.3 ，基底 Tensorflow 版本為 2.3.0 。</p>\n<p>假設我們想要建構一個輸入長度為 100 的向量，經過兩層輸出為 50 的隱藏層後，最後輸出長度為 10 的向量。</p>\n<p>在 Keras 中，我們可以使用很簡單的方式來建構一個序列模型。</p>\n<pre><code>import tensorflow as tf\nfrom keras.models import Model\nfrom keras.layers import Input,Dense\nfrom keras import backend as K\n\ndef SequenceModel():\n\n    # 輸入層\n    model_input = Input(shape=(100), name='input')\n    # 隱藏層 1 \n    hidden = Dense(50, activation='sigmoid',name=&quot;hidden_1&quot;)(model_input)\n    # 隱藏層 2 \n    hidden = Dense(50, activation='sigmoid',name=&quot;hidden_2&quot;)(hidden)\n    # 輸出層 \n    model_output = Dense(10, activation='sigmoid',name=&quot;output&quot;)(hidden)\n\n    model = Model(inputs=[model_input], outputs=[model_output])\n\n    return model\n</code></pre>\n<p>  可以看到由 Keras 建構只需要專心建構網路的架構，而不需要做 Weight 及 Bias 的數量及初始化定義，它會以預設的參數進行建構，若要修改也可以帶入引數進行設定。</p>\n<pre><code>keras.layers.Dense(units, \n                   activation=None, \n                   use_bias=True, \n                   kernel_initializer='glorot_uniform', bias_initializer='zeros', \n                   kernel_regularizer=None, \n                   bias_regularizer=None, \n                   activity_regularizer=None, \n                   kernel_constraint=None, \n                   bias_constraint=None)\n</code></pre>\n<p>若要了解更詳細的設定可以查看 <a href=\"https://keras.io/api/layers/core_layers/dense/\">Keras 手冊</a></p>\n<h3>卷積層</h3>\n<p>  若要建構一個 DNN ，卷積層是必須的，與全連接層相同的做法，只是呼叫的函式不同而已。</p>\n<p>  在接下來的範例中，輸入張量為 100x100x3 ，經過兩層 50 個卷積核為 3x3 ，Stride 為 2 ，不使用 Padding 的卷積層後，進行 Flatten ，最後再接入向量長度為 10 的輸出層。</p>\n<pre><code>import tensorflow as tf\nfrom keras.models import Model\nfrom keras.layers import Input,Dense,Conv2D\nfrom keras import backend as K\n\ndef SequenceModel():\n\n    # 輸入層\n    model_input = Input(shape=(100,100,3), name='input')\n    # 隱藏層 1 \n    hidden = Conv2D(50, (3, 3), activation='relu', padding='valid',name='hidden_1')(model_input)\n    # 隱藏層 2 \n    hidden = Conv2D(50, (3, 3), activation='relu', padding='valid',name='hidden_2')(model_input)\n    # Flatten\n    Flatten_layer = Flatten(name='flatten')(hidden)\n    # 輸出層 \n    model_output = Dense(10, activation='sigmoid',name=&quot;output&quot;)(Flatten_layer)\n\n    model = Model(inputs=[model_input], outputs=[model_output])\n\n    return model\n</code></pre>\n<p>同樣，這只是最基本的應用，若要更進階的使用請詳看 <a href=\"https://keras.io/api/layers/convolution_layers/\">Keras 手冊</a></p>\n<p>  以上，我們已經知道該怎麼建構卷積層及全連接層，使用這兩者已經可以建構一個影像辨識的應用，像是一開始的 AlexNet 及 VGG 系列都是使用單純的卷積加上全連接層建構而成的，接下來，你可以建構自己的架構嘗試進行影像辨識，可以使用<a href=\"http://yann.lecun.com/exdb/mnist/\">手寫辨識 MINST</a> 或是 <a href=\"https://www.kaggle.com/c/dogs-vs-cats\">Kaggle 的 Dogs v.s Cats</a> 進行練習。</p>\n",
            "tags": [
                "DNN"
            ]
        }
    ]
}