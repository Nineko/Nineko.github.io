<?xml version="1.0"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://nineko.github.io</id>
    <title>Nineko&#39;s Blog • Posts by &#34;dnn&#34; tag</title>
    <link href="https://nineko.github.io" />
    <updated>2020-08-03T07:55:22.000Z</updated>
    <category term="QT" />
    <category term="DNN" />
    <category term="Computer Vision" />
    <category term="Pose Estimation" />
    <entry>
        <id>https://nineko.github.io/2020/08/03/Note-BasicSequenceModel/</id>
        <title>[筆記]序列模型(1)-基本序列模型</title>
        <link rel="alternate" href="https://nineko.github.io/2020/08/03/Note-BasicSequenceModel/"/>
        <content type="html">&lt;h1&gt;目錄&lt;/h1&gt;
&lt;p&gt;&lt;strong&gt;基本序列模型&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;多尺度架構&lt;/p&gt;
&lt;p&gt;捷徑架構&lt;/p&gt;
&lt;h1&gt;基本序列模型&lt;/h1&gt;
&lt;p&gt;  序列模型為建構深度學習網路時最直觀也最簡便的方式，在大多數時候，序列模型往往能夠讓你在解決問題上提供一個初步的解決方案。&lt;/p&gt;
&lt;p&gt;不過儘管它如此單純，依舊值得好好研究，在本篇中將會從最基本的開始說明，也就是沒有任何特別操作，單純一層疊一層的方式來建構深度學習網路。&lt;/p&gt;
&lt;p&gt;這種方式在初期被大量使用，它方便架設，也很容易理解，但是它因簡單的架構，無法處理太過於複雜的特徵，也沒有任何機制去降低計算量，可說是有利有弊。&lt;/p&gt;
&lt;h2&gt;建構&lt;/h2&gt;
&lt;h3&gt;全連接層&lt;/h3&gt;
&lt;p&gt;在這個筆記裡，範例皆為 Keras 實做版本，Keras 版本為 2.4.3 ，基底 Tensorflow 版本為 2.3.0 。&lt;/p&gt;
&lt;p&gt;假設我們想要建構一個輸入長度為 100 的向量，經過兩層輸出為 50 的隱藏層後，最後輸出長度為 10 的向量。&lt;/p&gt;
&lt;p&gt;在 Keras 中，我們可以使用很簡單的方式來建構一個序列模型。&lt;/p&gt;
&lt;figure class=&#34;highlight python&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; tensorflow &lt;span class=&#34;keyword&#34;&gt;as&lt;/span&gt; tf&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; keras.models &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; Model&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; keras.layers &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; Input,Dense&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; keras &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; backend &lt;span class=&#34;keyword&#34;&gt;as&lt;/span&gt; K&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;function&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title&#34;&gt;SequenceModel&lt;/span&gt;():&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;comment&#34;&gt;# 輸入層&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    model_input = Input(shape=(&lt;span class=&#34;number&#34;&gt;100&lt;/span&gt;), name=&lt;span class=&#34;string&#34;&gt;&amp;#x27;input&amp;#x27;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;comment&#34;&gt;# 隱藏層 1 &lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    hidden = Dense(&lt;span class=&#34;number&#34;&gt;50&lt;/span&gt;, activation=&lt;span class=&#34;string&#34;&gt;&amp;#x27;sigmoid&amp;#x27;&lt;/span&gt;,name=&lt;span class=&#34;string&#34;&gt;&amp;quot;hidden_1&amp;quot;&lt;/span&gt;)(model_input)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;comment&#34;&gt;# 隱藏層 2 &lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    hidden = Dense(&lt;span class=&#34;number&#34;&gt;50&lt;/span&gt;, activation=&lt;span class=&#34;string&#34;&gt;&amp;#x27;sigmoid&amp;#x27;&lt;/span&gt;,name=&lt;span class=&#34;string&#34;&gt;&amp;quot;hidden_2&amp;quot;&lt;/span&gt;)(hidden)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;comment&#34;&gt;# 輸出層 &lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    model_output = Dense(&lt;span class=&#34;number&#34;&gt;10&lt;/span&gt;, activation=&lt;span class=&#34;string&#34;&gt;&amp;#x27;sigmoid&amp;#x27;&lt;/span&gt;,name=&lt;span class=&#34;string&#34;&gt;&amp;quot;output&amp;quot;&lt;/span&gt;)(hidden)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    model = Model(inputs=[model_input], outputs=[model_output])&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; model&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;  可以看到由 Keras 建構只需要專心建構網路的架構，而不需要做 Weight 及 Bias 的數量及初始化定義，它會以預設的參數進行建構，若要修改也可以帶入引數進行設定。&lt;/p&gt;
&lt;figure class=&#34;highlight python&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;keras.layers.Dense(units, &lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;                   activation=&lt;span class=&#34;literal&#34;&gt;None&lt;/span&gt;, &lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;                   use_bias=&lt;span class=&#34;literal&#34;&gt;True&lt;/span&gt;, &lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;                   kernel_initializer=&lt;span class=&#34;string&#34;&gt;&amp;#x27;glorot_uniform&amp;#x27;&lt;/span&gt;, bias_initializer=&lt;span class=&#34;string&#34;&gt;&amp;#x27;zeros&amp;#x27;&lt;/span&gt;, &lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;                   kernel_regularizer=&lt;span class=&#34;literal&#34;&gt;None&lt;/span&gt;, &lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;                   bias_regularizer=&lt;span class=&#34;literal&#34;&gt;None&lt;/span&gt;, &lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;                   activity_regularizer=&lt;span class=&#34;literal&#34;&gt;None&lt;/span&gt;, &lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;                   kernel_constraint=&lt;span class=&#34;literal&#34;&gt;None&lt;/span&gt;, &lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;                   bias_constraint=&lt;span class=&#34;literal&#34;&gt;None&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;若要了解更詳細的設定可以查看 &lt;a href=&#34;https://keras.io/api/layers/core_layers/dense/&#34;&gt;Keras 手冊&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;卷積層&lt;/h3&gt;
&lt;p&gt;  若要建構一個 DNN ，卷積層是必須的，與全連接層相同的做法，只是呼叫的函式不同而已。&lt;/p&gt;
&lt;p&gt;  在接下來的範例中，輸入張量為 100x100x3 ，經過兩層 50 個卷積核為 3x3 ，Stride 為 2 ，不使用 Padding 的卷積層後，進行 Flatten ，最後再接入向量長度為 10 的輸出層。&lt;/p&gt;
&lt;figure class=&#34;highlight python&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; tensorflow &lt;span class=&#34;keyword&#34;&gt;as&lt;/span&gt; tf&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; keras.models &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; Model&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; keras.layers &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; Input,Dense,Conv2D&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; keras &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; backend &lt;span class=&#34;keyword&#34;&gt;as&lt;/span&gt; K&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;function&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title&#34;&gt;SequenceModel&lt;/span&gt;():&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;comment&#34;&gt;# 輸入層&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    model_input = Input(shape=(&lt;span class=&#34;number&#34;&gt;100&lt;/span&gt;,&lt;span class=&#34;number&#34;&gt;100&lt;/span&gt;,&lt;span class=&#34;number&#34;&gt;3&lt;/span&gt;), name=&lt;span class=&#34;string&#34;&gt;&amp;#x27;input&amp;#x27;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;comment&#34;&gt;# 隱藏層 1 &lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    hidden = Conv2D(&lt;span class=&#34;number&#34;&gt;50&lt;/span&gt;, (&lt;span class=&#34;number&#34;&gt;3&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;3&lt;/span&gt;), activation=&lt;span class=&#34;string&#34;&gt;&amp;#x27;relu&amp;#x27;&lt;/span&gt;, padding=&lt;span class=&#34;string&#34;&gt;&amp;#x27;valid&amp;#x27;&lt;/span&gt;,name=&lt;span class=&#34;string&#34;&gt;&amp;#x27;hidden_1&amp;#x27;&lt;/span&gt;)(model_input)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;comment&#34;&gt;# 隱藏層 2 &lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    hidden = Conv2D(&lt;span class=&#34;number&#34;&gt;50&lt;/span&gt;, (&lt;span class=&#34;number&#34;&gt;3&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;3&lt;/span&gt;), activation=&lt;span class=&#34;string&#34;&gt;&amp;#x27;relu&amp;#x27;&lt;/span&gt;, padding=&lt;span class=&#34;string&#34;&gt;&amp;#x27;valid&amp;#x27;&lt;/span&gt;,name=&lt;span class=&#34;string&#34;&gt;&amp;#x27;hidden_2&amp;#x27;&lt;/span&gt;)(model_input)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;comment&#34;&gt;# Flatten&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    Flatten_layer = Flatten(name=&lt;span class=&#34;string&#34;&gt;&amp;#x27;flatten&amp;#x27;&lt;/span&gt;)(hidden)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;comment&#34;&gt;# 輸出層 &lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    model_output = Dense(&lt;span class=&#34;number&#34;&gt;10&lt;/span&gt;, activation=&lt;span class=&#34;string&#34;&gt;&amp;#x27;sigmoid&amp;#x27;&lt;/span&gt;,name=&lt;span class=&#34;string&#34;&gt;&amp;quot;output&amp;quot;&lt;/span&gt;)(Flatten_layer)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    model = Model(inputs=[model_input], outputs=[model_output])&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; model&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;同樣，這只是最基本的應用，若要更進階的使用請詳看 &lt;a href=&#34;https://keras.io/api/layers/convolution_layers/&#34;&gt;Keras 手冊&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;  以上，我們已經知道該怎麼建構卷積層及全連接層，使用這兩者已經可以建構一個影像辨識的應用，像是一開始的 AlexNet 及 VGG 系列都是使用單純的卷積加上全連接層建構而成的，接下來，你可以建構自己的架構嘗試進行影像辨識，可以使用&lt;a href=&#34;http://yann.lecun.com/exdb/mnist/&#34;&gt;手寫辨識 MINST&lt;/a&gt; 或是 &lt;a href=&#34;https://www.kaggle.com/c/dogs-vs-cats&#34;&gt;Kaggle 的 Dogs v.s Cats&lt;/a&gt; 進行練習。&lt;/p&gt;
</content>
        <category term="DNN" />
        <updated>2020-08-03T07:55:22.000Z</updated>
    </entry>
    <entry>
        <id>https://nineko.github.io/2020/07/30/MyPaper/</id>
        <title>Training Deep Networks with Synthetic Data for Textureless Object Pose Estimation</title>
        <link rel="alternate" href="https://nineko.github.io/2020/07/30/MyPaper/"/>
        <content type="html">&lt;p&gt;碩士研究成果，不過目前因其他因素，無法公開全文，也不適合作太詳細的說明，還請見諒&lt;br&gt;
最晚公開時間 2025.01&lt;/p&gt;
&lt;h1&gt;論文連結&lt;/h1&gt;  
&lt;p&gt;&lt;a href=&#34;https://drive.google.com/open?id=14RATn-h3gV4wIrBbZ2rxjERyxK64EEQM&#34;&gt;https://drive.google.com/open?id=14RATn-h3gV4wIrBbZ2rxjERyxK64EEQM&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://github.com/Nineko/Deep-Learning_Training-Deep-Networks-with-Synthetic-Data-for-Textureless&#34;&gt;Github Link&lt;/a&gt;&lt;/p&gt;
&lt;h1&gt;簡述&lt;/h1&gt;    
&lt;h2&gt;問題定義&lt;/h2&gt;
　　在這個研究中想要解決在工業應用上因傳統視覺伺服的不足而導入深度學習時，所發生的種種問題。
我們假設視覺系統為一個手眼系統(左圖)，所以能夠以物體為圓心定義出一個球座標系(右圖)
&lt;p&gt;&lt;img src=&#34;eyeonhand.png&#34; alt=&#34;image&#34;&gt;&lt;/p&gt;
&lt;p&gt;根據此座標系，在我們的研究中主要考慮三個變量 : In-plane Rotation 、 Theta 、 Phi&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;ThreePara.gif&#34; alt=&#34;image&#34;&gt;&lt;/p&gt;
&lt;h2&gt;CAD Simulator&lt;/h2&gt;
　　同時為了解決訓練資料取得及標定不易的問題，我們撰寫了使用OpenGL並在QT上進行開發的CAD模型模擬器，詳細可以前往我的 CAD-Simulator 專案(https://github.com/Nineko/CAD-Simulator)
&lt;p&gt;&lt;img src=&#34;CAD%E6%A8%A1%E5%9E%8B%E7%95%8C%E9%9D%A2.png&#34; alt=&#34;image&#34;&gt;&lt;/p&gt;
&lt;h2&gt;測試結果&lt;/h2&gt;
　　在本研究中，我們利用前述的模擬器產生訓練資料進行訓練，並以相同的方式產生測試集對三種物體進行測試，每種物體都產生了約16000張圖片進行測試
&lt;p&gt;&lt;img src=&#34;class.jpg&#34; alt=&#34;image&#34;&gt;&lt;/p&gt;
&lt;p&gt;測試時分成兩個部分，首先為分辨物體及物體定位的結果 :&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center&#34;&gt;Class&lt;/th&gt;
&lt;th style=&#34;text-align:center&#34;&gt;Mean IoU&lt;/th&gt;
&lt;th style=&#34;text-align:center&#34;&gt;Mean Classification Accuracy&lt;/th&gt;
&lt;th style=&#34;text-align:center&#34;&gt;Center X-Shift Error (By pixel)&lt;/th&gt;
&lt;th style=&#34;text-align:center&#34;&gt;Center Y-Shift Error (By pixel)&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Class 1&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;0.8824&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;0.8284&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;2.3140&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;2.2287&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Class 2&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;0.8592&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;0.8496&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;1.6883&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;1.6435&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Class 3&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;0.9362&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;0.8499&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;1.9301&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;1.6057&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;再來是三個變量的估測結果 :&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center&#34;&gt;Class&lt;/th&gt;
&lt;th style=&#34;text-align:center&#34;&gt;Mean In-plane rotation error(°)&lt;/th&gt;
&lt;th style=&#34;text-align:center&#34;&gt;Mean Theta error(°)&lt;/th&gt;
&lt;th style=&#34;text-align:center&#34;&gt;Mean Phi error(°)&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Class 1&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;2.7461&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;1.3171&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;6.2603&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Class 2&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;3.5969&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;0.8520&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;6.2455&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Class 3&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;4.6340&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;1.0070&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;6.0381&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
</content>
        <category term="DNN" />
        <category term="Computer Vision" />
        <category term="Pose Estimation" />
        <updated>2020-07-30T08:22:33.000Z</updated>
    </entry>
</feed>
